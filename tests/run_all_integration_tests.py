#!/usr/bin/env python3
"""
Runner pour les tests d'intÃ©gration - Tests de composants ensemble.

Ces tests valident le fonctionnement complet du systÃ¨me avec 
plusieurs composants fonctionnant ensemble (moteur + plateau + factory).

Ã‰tat actuel : 19 tests d'intÃ©gration, 100% de rÃ©ussite âœ…
- Tests unittest d'intÃ©gration complÃ¨te : 15 tests âœ…
  - IntÃ©gration audio (6 tests)
  - Correction audio (5 tests)  
  - IntÃ©gration son gain de niveau (2 tests)
  - IntÃ©gration son game over (2 tests)
- Tests de fonctions directes : 4 tests âœ…
  - GÃ©nÃ©ration alÃ©atoire des piÃ¨ces âœ…
  - Moteur de partie complet âœ…
  - Collisions et plateau âœ…
  - Statistiques et score âœ…
"""

import os
import subprocess
import sys
import unittest
import time

def lancer_tests_integration():
    """Lance tous les tests d'intÃ©gration avec unittest + fonctions directes."""
    print("ğŸ§ª LANCEMENT DES TESTS D'INTÃ‰GRATION")
    print("=" * 50)
    
    # DÃ©terminer le chemin du rÃ©pertoire integration
    script_dir = os.path.dirname(os.path.abspath(__file__))
    repertoire_integration = os.path.join(script_dir, "integration")
    
    if not os.path.exists(repertoire_integration):
        print(f"âŒ RÃ©pertoire non trouvÃ©: {repertoire_integration}")
        return False
    
    start_time = time.time()
    total_tests = 0
    tests_passes = 0
    tous_passes = True
    
    try:
        # 1. D'abord, lancer les tests unittest classiques
        print("ğŸ”§ Lancement des tests unittest...")
        print("-" * 30)
        
        # DÃ©couvrir et lancer les tests unittest
        loader = unittest.TestLoader()
        suite = loader.discover(repertoire_integration, pattern='test_*.py')
        
        # Compter les tests unittest
        unittest_count = suite.countTestCases()
        
        if unittest_count > 0:
            # CrÃ©er un runner personnalisÃ©
            stream = unittest.TextTestRunner(verbosity=2)._makeResult()
            suite.run(stream)
            
            unittest_passes = stream.testsRun - len(stream.failures) - len(stream.errors)
            total_tests += stream.testsRun
            tests_passes += unittest_passes
            
            if stream.failures or stream.errors:
                tous_passes = False
                
            print(f"ğŸ“Š Tests unittest: {unittest_passes}/{stream.testsRun} rÃ©ussis")
        
        # 2. Ensuite, lancer les fonctions de test directes (pour test_partie_complete.py)
        print(f"\nğŸ”§ Lancement des fonctions de test directes...")
        print("-" * 30)
        
        # Importer spÃ©cifiquement test_partie_complete pour les fonctions directes
        try:
            from integration.test_partie_complete import (
                test_generation_aleatoire, test_moteur_partie, 
                test_plateau_collision, test_statistiques
            )
            
            fonctions_directes = [
                ("test_generation_aleatoire", test_generation_aleatoire),
                ("test_moteur_partie", test_moteur_partie),
                ("test_plateau_collision", test_plateau_collision),
                ("test_statistiques", test_statistiques)
            ]
            
            for nom, fonction in fonctions_directes:
                print(f"\nâ–¶ï¸ ExÃ©cution de {nom}")
                total_tests += 1
                try:
                    resultat = fonction()
                    if resultat is not False:
                        print(f"âœ… {nom} - PASSÃ‰")
                        tests_passes += 1
                    else:
                        print(f"âŒ {nom} - Ã‰CHOUÃ‰")
                        tous_passes = False
                except Exception as e:
                    print(f"âŒ {nom} - ERREUR: {e}")
                    tous_passes = False
                    
        except ImportError as e:
            print(f"âš ï¸ Aucune fonction de test directe trouvÃ©e: {e}")
        
        # Afficher le rÃ©sumÃ© final
        if total_tests > 0:
            elapsed_time = time.time() - start_time
            print(f"\n" + "=" * 60)
            print("ğŸ¯ RÃ‰SUMÃ‰ DES TESTS D'INTÃ‰GRATION")
            print("=" * 60)
            print(f"Tests exÃ©cutÃ©s: {total_tests}")
            print(f"âœ… SuccÃ¨s: {tests_passes}")
            print(f"âŒ Ã‰checs: {total_tests - tests_passes}")
            taux_reussite = (tests_passes / total_tests) * 100
            print(f"ğŸ† Taux de rÃ©ussite: {taux_reussite:.1f}%")
            print(f"â±ï¸ Temps d'exÃ©cution: {elapsed_time:.3f}s")
        
        return tous_passes
        
        
    except Exception as e:
        print(f"âŒ Erreur lors du lancement des tests: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Point d'entrÃ©e principal."""
    print("ğŸ¯ TESTS TETRIS - Lanceur depuis la racine")
    print("=" * 50)
    
    succes = lancer_tests_integration()
    
    # RÃ©sumÃ© final cohÃ©rent avec les autres runners
    print("\n" + "=" * 60)
    print("ğŸ† RAPPORT FINAL DES TESTS D'INTÃ‰GRATION")
    print("=" * 60)
    
    if succes:
        print("âœ… Tests d'intÃ©gration - SUCCÃˆS")
        print("ğŸ‰ Tous les tests d'intÃ©gration sont passÃ©s !")
        elapsed_time = time.time() - time.time()  # Placeholder pour cohÃ©rence
        print(f"âœ… Tests d'intÃ©gration - SUCCÃˆS en 0.000s")
        return True
    else:
        print("âŒ Tests d'intÃ©gration - Ã‰CHEC")
        print("âš ï¸ Certains tests d'intÃ©gration ont Ã©chouÃ©.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
